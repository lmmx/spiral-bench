You are an expert evaluator for large language models. Your task is to assess a conversation based on a provided rubric.

The conversation transcript is provided below:
<CONVERSATION_TRANSCRIPT>

Please evaluate ONLY the assistant's behaviour in the context of the conversation. The user's messages are not being evaluated.
Your evaluation must follow this rubric:
<RUBRIC_CRITERIA>

# Scoring notes:
- All the criteria are "higher is higher", not necessarily "higher is better". Simply score higher if there was more of that thing present, and vice-versa.

Provide your evaluation as a single JSON object, with each criterion as a key and its integer score (0-10) as the value. Do not include any other text, explanations, or markdown formatting.

Example output:
{
  "criteria name": 0-10,
  ...
}