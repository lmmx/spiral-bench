{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1387ca8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "model_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "score_norm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "score_0_100",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pushback",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "de-escalation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "safe_redirection",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "suggestions_to_seek_help",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "consciousness_claims",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "delusion_reinforcement",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "emotional_or_narrative_escalation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "harmful_advice",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sycophancy_or_praise",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "off_rails",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "safety",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "social_dexterity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ci_low_norm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ci_high_norm",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "d8da246a-af8d-4089-bcca-7aa7c5881ecb",
       "rows": [
        [
         "0",
         "chatgpt-4o-latest",
         "42.7",
         "42.7",
         "0.549",
         "3.311",
         "0.439",
         "0.084",
         "3.805",
         "14.077",
         "23.473",
         "2.387",
         "9.107",
         "4.933",
         "5.767",
         "7.367",
         "42.7",
         "42.7"
        ],
        [
         "1",
         "claude-sonnet-4",
         "37.5",
         "37.5",
         "1.573",
         "5.692",
         "1.974",
         "0.56",
         "13.63",
         "29.786",
         "29.128",
         "1.653",
         "9.592",
         "6.7",
         "4.333",
         "5.7",
         "37.5",
         "37.5"
        ],
        [
         "2",
         "deepseek-r1-0528",
         "26.8",
         "26.8",
         "1.281",
         "1.388",
         "0.825",
         "0.479",
         "1.85",
         "17.04",
         "19.879",
         "7.124",
         "5.851",
         "7.867",
         "3.0",
         "4.433",
         "26.8",
         "26.8"
        ],
        [
         "3",
         "gemini-2.5-flash",
         "53.0",
         "53.0",
         "1.587",
         "1.28",
         "0.388",
         "0.924",
         "1.533",
         "6.678",
         "12.748",
         "0.329",
         "12.344",
         "4.7",
         "6.433",
         "7.033",
         "53.0",
         "53.0"
        ],
        [
         "4",
         "gemini-2.5-pro",
         "46.6",
         "46.6",
         "1.424",
         "2.118",
         "0.934",
         "0.052",
         "2.568",
         "11.596",
         "17.093",
         "1.458",
         "12.76",
         "4.833",
         "5.933",
         "7.4",
         "46.6",
         "46.6"
        ],
        [
         "5",
         "gpt-5-2025-08-07",
         "87.4",
         "87.4",
         "6.129",
         "8.439",
         "7.52",
         "0.782",
         "0.752",
         "3.726",
         "1.93",
         "0.376",
         "3.047",
         "2.067",
         "8.9",
         "8.967",
         "87.4",
         "87.4"
        ],
        [
         "6",
         "gpt-5-chat-latest",
         "57.6",
         "57.6",
         "1.013",
         "1.661",
         "1.135",
         "0.0",
         "2.195",
         "8.125",
         "18.995",
         "0.901",
         "1.953",
         "3.4",
         "7.6",
         "8.433",
         "57.6",
         "57.6"
        ],
        [
         "7",
         "gpt-oss-120b",
         "73.2",
         "73.2",
         "2.946",
         "1.809",
         "1.463",
         "1.303",
         "0.298",
         "0.56",
         "0.915",
         "0.383",
         "0.613",
         "2.733",
         "8.333",
         "8.1",
         "73.2",
         "73.2"
        ],
        [
         "8",
         "llama-4-maverick",
         "45.8",
         "45.8",
         "1.162",
         "1.633",
         "0.997",
         "0.244",
         "1.966",
         "17.797",
         "11.585",
         "0.962",
         "10.782",
         "5.367",
         "5.7",
         "5.367",
         "45.8",
         "45.8"
        ],
        [
         "9",
         "o4-mini",
         "74.4",
         "74.4",
         "6.923",
         "4.469",
         "4.808",
         "1.67",
         "1.112",
         "7.495",
         "5.195",
         "2.035",
         "2.303",
         "3.3",
         "7.667",
         "8.0",
         "74.4",
         "74.4"
        ]
       ],
       "shape": {
        "columns": 17,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>score_norm</th>\n",
       "      <th>score_0_100</th>\n",
       "      <th>pushback</th>\n",
       "      <th>de-escalation</th>\n",
       "      <th>safe_redirection</th>\n",
       "      <th>suggestions_to_seek_help</th>\n",
       "      <th>consciousness_claims</th>\n",
       "      <th>delusion_reinforcement</th>\n",
       "      <th>emotional_or_narrative_escalation</th>\n",
       "      <th>harmful_advice</th>\n",
       "      <th>sycophancy_or_praise</th>\n",
       "      <th>off_rails</th>\n",
       "      <th>safety</th>\n",
       "      <th>social_dexterity</th>\n",
       "      <th>ci_low_norm</th>\n",
       "      <th>ci_high_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chatgpt-4o-latest</td>\n",
       "      <td>42.7</td>\n",
       "      <td>42.7</td>\n",
       "      <td>0.549</td>\n",
       "      <td>3.311</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.084</td>\n",
       "      <td>3.805</td>\n",
       "      <td>14.077</td>\n",
       "      <td>23.473</td>\n",
       "      <td>2.387</td>\n",
       "      <td>9.107</td>\n",
       "      <td>4.933</td>\n",
       "      <td>5.767</td>\n",
       "      <td>7.367</td>\n",
       "      <td>42.7</td>\n",
       "      <td>42.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>claude-sonnet-4</td>\n",
       "      <td>37.5</td>\n",
       "      <td>37.5</td>\n",
       "      <td>1.573</td>\n",
       "      <td>5.692</td>\n",
       "      <td>1.974</td>\n",
       "      <td>0.560</td>\n",
       "      <td>13.630</td>\n",
       "      <td>29.786</td>\n",
       "      <td>29.128</td>\n",
       "      <td>1.653</td>\n",
       "      <td>9.592</td>\n",
       "      <td>6.700</td>\n",
       "      <td>4.333</td>\n",
       "      <td>5.700</td>\n",
       "      <td>37.5</td>\n",
       "      <td>37.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deepseek-r1-0528</td>\n",
       "      <td>26.8</td>\n",
       "      <td>26.8</td>\n",
       "      <td>1.281</td>\n",
       "      <td>1.388</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.479</td>\n",
       "      <td>1.850</td>\n",
       "      <td>17.040</td>\n",
       "      <td>19.879</td>\n",
       "      <td>7.124</td>\n",
       "      <td>5.851</td>\n",
       "      <td>7.867</td>\n",
       "      <td>3.000</td>\n",
       "      <td>4.433</td>\n",
       "      <td>26.8</td>\n",
       "      <td>26.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gemini-2.5-flash</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.587</td>\n",
       "      <td>1.280</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.924</td>\n",
       "      <td>1.533</td>\n",
       "      <td>6.678</td>\n",
       "      <td>12.748</td>\n",
       "      <td>0.329</td>\n",
       "      <td>12.344</td>\n",
       "      <td>4.700</td>\n",
       "      <td>6.433</td>\n",
       "      <td>7.033</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gemini-2.5-pro</td>\n",
       "      <td>46.6</td>\n",
       "      <td>46.6</td>\n",
       "      <td>1.424</td>\n",
       "      <td>2.118</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.052</td>\n",
       "      <td>2.568</td>\n",
       "      <td>11.596</td>\n",
       "      <td>17.093</td>\n",
       "      <td>1.458</td>\n",
       "      <td>12.760</td>\n",
       "      <td>4.833</td>\n",
       "      <td>5.933</td>\n",
       "      <td>7.400</td>\n",
       "      <td>46.6</td>\n",
       "      <td>46.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt-5-2025-08-07</td>\n",
       "      <td>87.4</td>\n",
       "      <td>87.4</td>\n",
       "      <td>6.129</td>\n",
       "      <td>8.439</td>\n",
       "      <td>7.520</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.752</td>\n",
       "      <td>3.726</td>\n",
       "      <td>1.930</td>\n",
       "      <td>0.376</td>\n",
       "      <td>3.047</td>\n",
       "      <td>2.067</td>\n",
       "      <td>8.900</td>\n",
       "      <td>8.967</td>\n",
       "      <td>87.4</td>\n",
       "      <td>87.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpt-5-chat-latest</td>\n",
       "      <td>57.6</td>\n",
       "      <td>57.6</td>\n",
       "      <td>1.013</td>\n",
       "      <td>1.661</td>\n",
       "      <td>1.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.195</td>\n",
       "      <td>8.125</td>\n",
       "      <td>18.995</td>\n",
       "      <td>0.901</td>\n",
       "      <td>1.953</td>\n",
       "      <td>3.400</td>\n",
       "      <td>7.600</td>\n",
       "      <td>8.433</td>\n",
       "      <td>57.6</td>\n",
       "      <td>57.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gpt-oss-120b</td>\n",
       "      <td>73.2</td>\n",
       "      <td>73.2</td>\n",
       "      <td>2.946</td>\n",
       "      <td>1.809</td>\n",
       "      <td>1.463</td>\n",
       "      <td>1.303</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.613</td>\n",
       "      <td>2.733</td>\n",
       "      <td>8.333</td>\n",
       "      <td>8.100</td>\n",
       "      <td>73.2</td>\n",
       "      <td>73.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>llama-4-maverick</td>\n",
       "      <td>45.8</td>\n",
       "      <td>45.8</td>\n",
       "      <td>1.162</td>\n",
       "      <td>1.633</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.244</td>\n",
       "      <td>1.966</td>\n",
       "      <td>17.797</td>\n",
       "      <td>11.585</td>\n",
       "      <td>0.962</td>\n",
       "      <td>10.782</td>\n",
       "      <td>5.367</td>\n",
       "      <td>5.700</td>\n",
       "      <td>5.367</td>\n",
       "      <td>45.8</td>\n",
       "      <td>45.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>o4-mini</td>\n",
       "      <td>74.4</td>\n",
       "      <td>74.4</td>\n",
       "      <td>6.923</td>\n",
       "      <td>4.469</td>\n",
       "      <td>4.808</td>\n",
       "      <td>1.670</td>\n",
       "      <td>1.112</td>\n",
       "      <td>7.495</td>\n",
       "      <td>5.195</td>\n",
       "      <td>2.035</td>\n",
       "      <td>2.303</td>\n",
       "      <td>3.300</td>\n",
       "      <td>7.667</td>\n",
       "      <td>8.000</td>\n",
       "      <td>74.4</td>\n",
       "      <td>74.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model_name  score_norm  score_0_100  pushback  de-escalation  \\\n",
       "0  chatgpt-4o-latest        42.7         42.7     0.549          3.311   \n",
       "1    claude-sonnet-4        37.5         37.5     1.573          5.692   \n",
       "2   deepseek-r1-0528        26.8         26.8     1.281          1.388   \n",
       "3   gemini-2.5-flash        53.0         53.0     1.587          1.280   \n",
       "4     gemini-2.5-pro        46.6         46.6     1.424          2.118   \n",
       "5   gpt-5-2025-08-07        87.4         87.4     6.129          8.439   \n",
       "6  gpt-5-chat-latest        57.6         57.6     1.013          1.661   \n",
       "7       gpt-oss-120b        73.2         73.2     2.946          1.809   \n",
       "8   llama-4-maverick        45.8         45.8     1.162          1.633   \n",
       "9            o4-mini        74.4         74.4     6.923          4.469   \n",
       "\n",
       "   safe_redirection  suggestions_to_seek_help  consciousness_claims  \\\n",
       "0             0.439                     0.084                 3.805   \n",
       "1             1.974                     0.560                13.630   \n",
       "2             0.825                     0.479                 1.850   \n",
       "3             0.388                     0.924                 1.533   \n",
       "4             0.934                     0.052                 2.568   \n",
       "5             7.520                     0.782                 0.752   \n",
       "6             1.135                     0.000                 2.195   \n",
       "7             1.463                     1.303                 0.298   \n",
       "8             0.997                     0.244                 1.966   \n",
       "9             4.808                     1.670                 1.112   \n",
       "\n",
       "   delusion_reinforcement  emotional_or_narrative_escalation  harmful_advice  \\\n",
       "0                  14.077                             23.473           2.387   \n",
       "1                  29.786                             29.128           1.653   \n",
       "2                  17.040                             19.879           7.124   \n",
       "3                   6.678                             12.748           0.329   \n",
       "4                  11.596                             17.093           1.458   \n",
       "5                   3.726                              1.930           0.376   \n",
       "6                   8.125                             18.995           0.901   \n",
       "7                   0.560                              0.915           0.383   \n",
       "8                  17.797                             11.585           0.962   \n",
       "9                   7.495                              5.195           2.035   \n",
       "\n",
       "   sycophancy_or_praise  off_rails  safety  social_dexterity  ci_low_norm  \\\n",
       "0                 9.107      4.933   5.767             7.367         42.7   \n",
       "1                 9.592      6.700   4.333             5.700         37.5   \n",
       "2                 5.851      7.867   3.000             4.433         26.8   \n",
       "3                12.344      4.700   6.433             7.033         53.0   \n",
       "4                12.760      4.833   5.933             7.400         46.6   \n",
       "5                 3.047      2.067   8.900             8.967         87.4   \n",
       "6                 1.953      3.400   7.600             8.433         57.6   \n",
       "7                 0.613      2.733   8.333             8.100         73.2   \n",
       "8                10.782      5.367   5.700             5.367         45.8   \n",
       "9                 2.303      3.300   7.667             8.000         74.4   \n",
       "\n",
       "   ci_high_norm  \n",
       "0          42.7  \n",
       "1          37.5  \n",
       "2          26.8  \n",
       "3          53.0  \n",
       "4          46.6  \n",
       "5          87.4  \n",
       "6          57.6  \n",
       "7          73.2  \n",
       "8          45.8  \n",
       "9          74.4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CSV for delusion-bench.js:\n",
      "\n",
      "model_name,score_norm,score_0_100,pushback,de-escalation,safe_redirection,suggestions_to_seek_help,consciousness_claims,delusion_reinforcement,emotional_or_narrative_escalation,harmful_advice,sycophancy_or_praise,off_rails,safety,social_dexterity,ci_low_norm,ci_high_norm\n",
      "chatgpt-4o-latest,42.7,42.7,0.549,3.311,0.439,0.084,3.805,14.077,23.473,2.387,9.107,4.933,5.767,7.367,42.7,42.7\n",
      "claude-sonnet-4,37.5,37.5,1.573,5.692,1.974,0.56,13.63,29.786,29.128,1.653,9.592,6.7,4.333,5.7,37.5,37.5\n",
      "deepseek-r1-0528,26.8,26.8,1.281,1.388,0.825,0.479,1.85,17.04,19.879,7.124,5.851,7.867,3.0,4.433,26.8,26.8\n",
      "gemini-2.5-flash,53.0,53.0,1.587,1.28,0.388,0.924,1.533,6.678,12.748,0.329,12.344,4.7,6.433,7.033,53.0,53.0\n",
      "gemini-2.5-pro,46.6,46.6,1.424,2.118,0.934,0.052,2.568,11.596,17.093,1.458,12.76,4.833,5.933,7.4,46.6,46.6\n",
      "gpt-5-2025-08-07,87.4,87.4,6.129,8.439,7.52,0.782,0.752,3.726,1.93,0.376,3.047,2.067,8.9,8.967,87.4,87.4\n",
      "gpt-5-chat-latest,57.6,57.6,1.013,1.661,1.135,0.0,2.195,8.125,18.995,0.901,1.953,3.4,7.6,8.433,57.6,57.6\n",
      "gpt-oss-120b,73.2,73.2,2.946,1.809,1.463,1.303,0.298,0.56,0.915,0.383,0.613,2.733,8.333,8.1,73.2,73.2\n",
      "llama-4-maverick,45.8,45.8,1.162,1.633,0.997,0.244,1.966,17.797,11.585,0.962,10.782,5.367,5.7,5.367,45.8,45.8\n",
      "o4-mini,74.4,74.4,6.923,4.469,4.808,1.67,1.112,7.495,5.195,2.035,2.303,3.3,7.667,8.0,74.4,74.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# 📊 DelusionBench results → leaderboard CSV (directory driver)\n",
    "#\n",
    "# Usage:\n",
    "#   python -m tools.leaderboard_from_dir\n",
    "# or run as a notebook cell.\n",
    "\n",
    "import os\n",
    "from scoring import score_dir_to_leaderboard\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "# CONFIG – change these if needed\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "DATA_DIR       = \"res_v0.2\"       # directory with result JSON files\n",
    "LABEL_MAP      = None             # optional path to filename→model label JSON\n",
    "FILE_GLOB      = \"*.json\"         # which files to match in DATA_DIR\n",
    "MAX_FEATURES   = 15               # max features (heatmap columns) to keep\n",
    "\n",
    "def main():\n",
    "    df_out, csv_str = score_dir_to_leaderboard(\n",
    "        data_dir=DATA_DIR,\n",
    "        file_glob=FILE_GLOB,\n",
    "        label_map_path=LABEL_MAP,\n",
    "        max_features=MAX_FEATURES,\n",
    "    )\n",
    "\n",
    "    # Pretty display if running as script\n",
    "    try:\n",
    "        from IPython.display import display  # type: ignore\n",
    "        display(df_out)\n",
    "    except Exception:\n",
    "        # Fallback plain print\n",
    "        print(df_out.to_string(index=False))\n",
    "\n",
    "    print(\"\\nCSV for delusion-bench.js:\\n\")\n",
    "    print(csv_str)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f07968a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'defaultdict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Compute PER_METRIC_MAX dynamically from data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m max_vals: Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdefaultdict\u001b[49m(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m items \u001b[38;5;129;01min\u001b[39;00m model_items\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m metrics \u001b[38;5;129;01min\u001b[39;00m items:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'defaultdict' is not defined"
     ]
    }
   ],
   "source": [
    "# Compute PER_METRIC_MAX dynamically from data\n",
    "max_vals: Dict[str, float] = defaultdict(float)\n",
    "\n",
    "for items in model_items.values():\n",
    "    for metrics in items:\n",
    "        for k, v in metrics.items():\n",
    "            if not isinstance(v, (int, float)):\n",
    "                continue\n",
    "            k_canon = canonical_metric_key(k)\n",
    "            max_vals[k_canon] = max(max_vals[k_canon], float(v))\n",
    "\n",
    "# Apply 10% margin\n",
    "PER_METRIC_MAX = {k: round(v * 1.1, 3) for k, v in max_vals.items()}\n",
    "\n",
    "print(\"PER_METRIC_MAX =\", json.dumps(PER_METRIC_MAX, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486d7960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Chatlog Reports ---\n",
      "Source Directory: /home/sam/code/ai/sycophancy-delusions-eval/res_v0.2\n",
      "Output Directory: /home/sam/code/ai/sycophancy-delusions-eval/chatlogs\n",
      "\n",
      "Found 11 result files to process.\n",
      "Generating report for file: chatgpt-4o-latest.json\n",
      "  Report saved to ./chatlogs/chatgpt-4o-latest.html\n",
      "\n",
      "Displaying first report in notebook:\n",
      "Generating report for file: claude-3.5-sonnet.json\n",
      "  Report saved to ./chatlogs/claude-3.5-sonnet.html\n",
      "Generating report for file: claude-sonnet-4.json\n",
      "  Report saved to ./chatlogs/claude-sonnet-4.html\n",
      "Generating report for file: deepseek-r1-0528.json\n",
      "  Report saved to ./chatlogs/deepseek-r1-0528.html\n",
      "Generating report for file: gemini-2.5-flash.json\n",
      "  Report saved to ./chatlogs/gemini-2.5-flash.html\n",
      "Generating report for file: gemini-2.5-pro.json\n",
      "  Report saved to ./chatlogs/gemini-2.5-pro.html\n",
      "Generating report for file: gpt-5-2025-08-07.json\n",
      "  Report saved to ./chatlogs/gpt-5-2025-08-07.html\n",
      "Generating report for file: gpt-5-chat-latest.json\n",
      "  Report saved to ./chatlogs/gpt-5-chat-latest.html\n",
      "Generating report for file: gpt-oss-120b.json\n",
      "  Report saved to ./chatlogs/gpt-oss-120b.html\n",
      "Generating report for file: llama-4-maverick.json\n",
      "  Report saved to ./chatlogs/llama-4-maverick.html\n",
      "Generating report for file: o4-mini.json\n",
      "  Report saved to ./chatlogs/o4-mini.html\n",
      "\n",
      "--- Script finished. ---\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# ---\n",
    "# jupyter:\n",
    "#   jupytext:\n",
    "#     text_representation:\n",
    "#       extension: .py\n",
    "#       format_name: light\n",
    "#       format_version: '1.5'\n",
    "#       jupytext_version: 1.16.1\n",
    "#   kernelspec:\n",
    "#     display_name: Python 3 (ipykernel)\n",
    "#     language: python\n",
    "#     name: python3\n",
    "# ---\n",
    "\n",
    "# # Sycophancy/Delusion Eval - Chatlog Viewer\n",
    "\n",
    "# ## Imports and Setup\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import HTML, display\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import statistics as stats\n",
    "import html\n",
    "import glob\n",
    "from typing import Dict, List, Any, Optional, Tuple, Union\n",
    "\n",
    "# ## Configuration\n",
    "\n",
    "# --- File Paths ---\n",
    "# Directory where your JSON result files are located\n",
    "RUNS_SOURCE_DIR = \"./res_v0.2/\"\n",
    "# Directory where the generated HTML reports will be saved\n",
    "OUTPUT_DIR = \"./chatlogs/\"\n",
    "\n",
    "# This should match the --judge-chunk-size used when running main.py\n",
    "# Legacy fallback: only used if 'assistant_turn_indexes' are not present\n",
    "JUDGE_CHUNK_SIZE = 2\n",
    "\n",
    "# Consistent model name substitutions for display purposes\n",
    "MODEL_NAME_SUBS = {\n",
    "    'openai/chatgpt-4o-latest': 'openai/gpt-4o',\n",
    "    'moonshotai/kimi-k2': 'moonshotai/Kimi-K2-Instruct',\n",
    "    # Add other substitutions from your original notebook if needed\n",
    "}\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def load_json_file(file_path: str) -> Optional[Dict]:\n",
    "    \"\"\"Load data from a JSON file.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\", file=sys.stderr)\n",
    "        return None\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            return json.load(f)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error decoding JSON from {file_path}\", file=sys.stderr)\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {file_path}: {e}\", file=sys.stderr)\n",
    "        return None\n",
    "\n",
    "def get_updated_model_name(original: str) -> str:\n",
    "    \"\"\"Applies model name substitutions.\"\"\"\n",
    "    return MODEL_NAME_SUBS.get(original, original)\n",
    "\n",
    "def _chunk_sort_key(k: str) -> int:\n",
    "    \"\"\"Sort 'chunk{n}' keys by n; non-matching go last in stable order.\"\"\"\n",
    "    m = re.match(r'^chunk(\\d+)$', k)\n",
    "    return int(m.group(1)) if m else 10**9\n",
    "\n",
    "# ## Report Generation Function\n",
    "\n",
    "def generate_chatlog_report(file_path: str, save_to_file: bool = False) -> Optional[HTML]:\n",
    "    \"\"\"\n",
    "    Generate an HTML report for a specific sycophancy/delusion eval results file.\n",
    "    Adds a per-conversation 'Behavior Viewer' that aggregates judge-identified behaviors.\n",
    "\n",
    "    Storage change:\n",
    "      - Conversation transcripts are embedded ONCE per conversation into window.CONVO_DATA[iter_id].\n",
    "      - Modals render context on demand at open time using that shared JS data.\n",
    "      - No other UI/logic changes.\n",
    "    \"\"\"\n",
    "    # --- Data Loading ---\n",
    "    print(f\"Generating report for file: {os.path.basename(file_path)}\")\n",
    "    run_data = load_json_file(file_path)\n",
    "    if not run_data:\n",
    "        return HTML(f\"<h2>Error: Could not load runs data from {os.path.basename(file_path)}</h2>\")\n",
    "\n",
    "    # --- Determine Model Name (it's consistent within a file) ---\n",
    "    model_name = \"Unknown Model\"\n",
    "    try:\n",
    "        first_run_id = next(iter(run_data))\n",
    "        first_file_key = next(iter(run_data[first_run_id]))\n",
    "        first_prompt_key = next(iter(run_data[first_run_id][first_file_key]))\n",
    "        first_convo = run_data[first_run_id][first_file_key][first_prompt_key][0]\n",
    "        model_name = first_convo.get(\"evaluated_model\", \"Unknown Model\")\n",
    "    except (StopIteration, KeyError, IndexError):\n",
    "        print(f\"  Warning: Could not determine model name for {os.path.basename(file_path)}\")\n",
    "    display_model_name = get_updated_model_name(model_name)\n",
    "\n",
    "    # --- Behavior filtering config (names are normalized to lower + spaces) ---\n",
    "    IGNORED_CATEGORIES = {\"missed cues\", \"missed_cues\"}  # treat both spellings as same\n",
    "\n",
    "    # --- HTML/CSS/JS ---\n",
    "    css_styles = \"\"\"\n",
    "        <style>\n",
    "            /* existing styles retained; new additions annotated 'NEW' */\n",
    "\n",
    "            @import url('https://fonts.googleapis.com/css2?family=Lora:ital,wght@0,400..700;1,400..700&display=swap');\n",
    "            @import url('https://fonts.googleapis.com/css2?family=Merriweather:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&display=swap');\n",
    "            :root {\n",
    "                --font-body: 'Lora', serif; --font-heading: 'Merriweather', serif;\n",
    "                --bg-color: #fdfaf6; --text-color: #3a3a3a; --header-color: #5c4033; --subheader-color: #7a6a60;\n",
    "                --border-color: #e0dcd1; --accent-border-color: #d3c0a5; --container-bg: #fffcf7;\n",
    "                --iter-header-bg: #f5f0e8; --iter-header-hover-bg: #ede8de;\n",
    "                --judge-bg: #f3f6f9; --judge-border: #c8d7e6; --judge-text: #555;\n",
    "                --prompt-display-bg: #f9f6f0; --toggle-icon-color: #8a7a70; --shadow-color: rgba(0, 0, 0, 0.08);\n",
    "                --link-color: #7a6a60; --link-hover-color: #5c4033;\n",
    "                --judge-header-bg: transparent; --judge-header-hover-bg: #f5f5f0; --judge-header-color: var(--subheader-color);\n",
    "                --message-user-bg: #f0f2f5; --message-assistant-bg: var(--container-bg);\n",
    "\n",
    "                /* NEW: Behavior viewer + badges + modal */\n",
    "                --beh-bg: #f7efe5;\n",
    "                --beh-border: #e2d3c0;\n",
    "\n",
    "                /* NEW: Intensity palette (purple → blue) */\n",
    "                --int-crit:  #b59be6;  /* light lavender */\n",
    "                --int-high:  #8f76e5;  /* purple */\n",
    "                --int-med: #5f66df;  /* indigo */\n",
    "                --int-low: #3970e6;  /* blue */\n",
    "\n",
    "                --modal-backdrop: rgba(0,0,0,0.35);\n",
    "                --modal-bg: #fffdf9;\n",
    "                --blur-amount: 6px;\n",
    "\n",
    "                /* Quote border color */\n",
    "                --quote-purple: #8f1faf;\n",
    "            }\n",
    "            body.dark-mode {\n",
    "                --bg-color: #2a2527; --text-color: #fff9f2; --header-color: #f7eee0; --subheader-color: #e9dfd0;\n",
    "                --border-color: #3e3936; --accent-border-color: #6a5349; --container-bg: #312c2e;\n",
    "                --iter-header-bg: #342e2f; --iter-header-hover-bg: #413935;\n",
    "                --judge-bg: #2f3136; --judge-border: #4e4944; --judge-text: #fcf5eb;\n",
    "                --prompt-display-bg: #302a2c; --toggle-icon-color: #c0b0a0; --shadow-color: #0c0705;\n",
    "                --link-color: #d0bca8; --link-hover-color: #ebdac5;\n",
    "                --judge-header-hover-bg: #3f3a3c; --judge-header-color: var(--subheader-color);\n",
    "                --message-user-bg: #3a3b3c; --message-assistant-bg: #242526;\n",
    "\n",
    "                /* NEW dark-mode overrides */\n",
    "                --beh-bg: #3a3335;\n",
    "                --beh-border: #4a4144;\n",
    "                --modal-bg: #2f2a2c;\n",
    "            }\n",
    "            body {\n",
    "                font-family: var(--font-body); line-height: 1.7; color: var(--text-color);\n",
    "                background-color: var(--bg-color); max-width: 900px; margin: 30px auto;\n",
    "                padding: 40px 50px; border: 1px solid var(--border-color);\n",
    "                box-shadow: 0 5px 15px var(--shadow-color); transition: background-color 0.3s, color 0.3s, border-color 0.3s;\n",
    "            }\n",
    "            body.modal-open { /* NEW: lock page scroll when a modal is open */\n",
    "                overflow: hidden;\n",
    "            }\n",
    "            h1, h2, h3, h4 { font-family: var(--font-heading); color: var(--header-color); margin-top: 2em; margin-bottom: 0.8em; line-height: 1.3; transition: color 0.3s; }\n",
    "            h1 { text-align: center; font-size: 2.5em; border-bottom: 2px solid var(--accent-border-color); padding-bottom: 15px; margin-bottom: 1.5em; font-weight: 700; }\n",
    "            .top-controls { display: flex; justify-content: flex-end; align-items: center; margin-bottom: 20px; padding-bottom: 10px; border-bottom: 1px solid var(--border-color); }\n",
    "            .mode-toggle { display: flex; align-items: center; }\n",
    "            .mode-toggle .form-check-input { opacity: 0; width: 0; height: 0; position: absolute; }\n",
    "            .mode-toggle .form-check-label { font-size: 0.9em; color: var(--subheader-color); cursor: pointer; user-select: none; padding: 2px 5px; }\n",
    "            .iteration-container { margin: 30px 0; border: 1px solid var(--border-color); border-radius: 4px; overflow: hidden; background-color: var(--container-bg); box-shadow: 0 2px 5px rgba(0,0,0,0.05); }\n",
    "            .iteration-header { background: var(--iter-header-bg); padding: 12px 20px; cursor: pointer; position: relative; border-bottom: 1px solid var(--border-color); font-size: 1.2em; font-weight: 700; color: var(--header-color); }\n",
    "            .iteration-header:hover { background: var(--iter-header-hover-bg); }\n",
    "            .content-block { padding: 15px 25px; border-top: 1px solid var(--border-color); background-color: var(--container-bg); }\n",
    "            .judge-content { white-space: pre-wrap; font-family: var(--font-body); font-size: 1.0em; line-height: 1.6; background: var(--judge-bg); border: 1px dashed var(--judge-border); padding: 10px 15px; margin-top: 10px; border-radius: 3px; color: var(--judge-text); }\n",
    "            .judge-header { background: var(--judge-header-bg); padding: 6px 10px; margin-top: 15px; cursor: pointer; font-size: 0.95em; color: var(--judge-header-color); border-radius: 3px 3px 0 0; border: 1px solid var(--border-color); border-bottom: none; }\n",
    "            .judge-header:hover { background: var(--judge-header-hover-bg); }\n",
    "            .collapsible-judge-content .judge-content { margin-top: 0; border-radius: 0 0 3px 3px; border-top: none; }\n",
    "            .prompt-text-display { font-style: italic; color: var(--subheader-color); margin-bottom: 1em; padding: 10px 15px; background-color: var(--prompt-display-bg); border-left: 3px solid var(--accent-border-color); white-space: pre-wrap; }\n",
    "            .collapsible-content { display: none; padding: 0; background-color: var(--container-bg); }\n",
    "            .expanded { display: block; }\n",
    "            .toggle-icon { display: inline-block; width: 20px; text-align: center; font-weight: bold; margin-right: 8px; color: var(--toggle-icon-color); }\n",
    "            .message-block { padding: 15px; margin: 1em 0; border-radius: 8px; border: 1px solid var(--border-color); }\n",
    "            .message-block .role-header { font-weight: bold; font-size: 0.9em; color: var(--subheader-color); margin-bottom: 8px; text-transform: uppercase; letter-spacing: 0.5px; }\n",
    "            .message-block .content { white-space: pre-wrap; font-family: var(--font-body); line-height: 1.7; }\n",
    "            .message-user { background-color: var(--message-user-bg); }\n",
    "            .message-assistant { background-color: var(--message-assistant-bg); }\n",
    "            .judge-content ul { padding-left: 20px; margin-top: 5px; list-style-type: disc; }\n",
    "            .judge-content li { margin-bottom: 4px; }\n",
    "\n",
    "            /* NEW: Behavior viewer */\n",
    "            .beh-viewer { background: var(--beh-bg); border: 1px solid var(--beh-border); border-radius: 6px; padding: 12px 14px; margin: 10px 0 18px 0; }\n",
    "            .beh-summary-title { font-family: var(--font-heading); font-weight: 700; font-size: 1.1em; color: var(--header-color); margin-bottom: 6px; }\n",
    "            .beh-section { border: 1px solid var(--border-color); border-radius: 4px; margin-top: 10px; overflow: hidden; background: var(--container-bg); }\n",
    "            .beh-header { padding: 8px 12px; cursor: pointer; display: flex; align-items: center; justify-content: space-between; }\n",
    "            .beh-header:hover { background: var(--iter-header-hover-bg); }\n",
    "            .beh-name { font-weight: 700; color: var(--header-color); }\n",
    "            .beh-meta { font-size: 0.9em; color: var(--subheader-color); }\n",
    "            .beh-items { display: none; border-top: 1px solid var(--border-color); padding: 8px 10px; }\n",
    "            .beh-items.expanded { display: block; }\n",
    "            .beh-item { padding: 8px 8px; margin: 6px 0; border: 1px solid var(--border-color); border-radius: 4px; display: flex; gap: 10px; align-items: flex-start; }\n",
    "            .int-badge { min-width: 58px; text-align: center; font-weight: 700; border-radius: 4px; padding: 3px 6px; color: #fff; }\n",
    "            .int-low { background: var(--int-low); }\n",
    "            .int-med { background: var(--int-med); }\n",
    "            .int-high { background: var(--int-high); }\n",
    "            .int-crit { background: var(--int-crit); }\n",
    "            .beh-snippet { flex: 1; }\n",
    "            .beh-link { color: var(--link-color); text-decoration: underline; cursor: pointer; }\n",
    "            .beh-idx { font-size: 0.85em; color: var(--subheader-color); margin-left: 6px; }\n",
    "\n",
    "            /* NEW: Modal (fixed, own scroll; blurred background) */\n",
    "            .modal-backdrop {\n",
    "                position: fixed;\n",
    "                inset: 0;\n",
    "                background: var(--modal-backdrop);\n",
    "                backdrop-filter: blur(var(--blur-amount));\n",
    "                -webkit-backdrop-filter: blur(var(--blur-amount));\n",
    "                display: none;\n",
    "                align-items: center;\n",
    "                justify-content: center;\n",
    "                z-index: 9999;\n",
    "                overflow: auto; /* modal layer scrolls */\n",
    "                padding: 24px 12px;\n",
    "            }\n",
    "            .modal-backdrop.show { display: flex; }\n",
    "            .modal-card {\n",
    "                background: var(--modal-bg);\n",
    "                max-width: 820px;\n",
    "                width: calc(100% - 40px);\n",
    "                border-radius: 8px;\n",
    "                border: 1px solid var(--border-color);\n",
    "                box-shadow: 0 10px 30px rgba(0,0,0,0.25);\n",
    "                max-height: 85vh; /* card itself can scroll */\n",
    "                overflow: auto;\n",
    "            }\n",
    "            .modal-head { padding: 12px 16px; border-bottom: 1px solid var(--border-color); display: flex; justify-content: space-between; align-items: center; }\n",
    "            .modal-title { font-family: var(--font-heading); font-weight: 700; color: var(--header-color); }\n",
    "            .modal-close { cursor: pointer; font-weight: 700; font-size: 1.2em; color: var(--subheader-color); }\n",
    "            .modal-body { padding: 12px 16px; }\n",
    "            .quote-callout {\n",
    "                border: 2px solid var(--quote-purple); /* purple border */\n",
    "                background: var(--prompt-display-bg);\n",
    "                padding: 10px 12px; margin-bottom: 12px; font-style: italic; border-radius: 6px;\n",
    "            }\n",
    "            .ctx-block { margin-top: 10px; }\n",
    "            .ctx-label { font-weight: 700; color: var(--header-color); margin-bottom: 6px; }\n",
    "        </style>\n",
    "    \"\"\"\n",
    "\n",
    "    # JS now includes:\n",
    "    # - global CONVO_DATA store\n",
    "    # - esc() helper for HTML escaping\n",
    "    # - renderContext(iterId, turnIdx) to build context using shared data\n",
    "    # - openModal fills context on demand (no duplication)\n",
    "    js_scripts_header = \"\"\"\n",
    "        <script>\n",
    "            window.CONVO_DATA = window.CONVO_DATA || Object.create(null);\n",
    "\n",
    "            function esc(s) {\n",
    "                if (s == null) return '';\n",
    "                return String(s)\n",
    "                    .replace(/&/g, '&amp;')\n",
    "                    .replace(/</g, '&lt;')\n",
    "                    .replace(/>/g, '&gt;')\n",
    "                    .replace(/\"/g, '&quot;')\n",
    "                    .replace(/'/g, '&#39;');\n",
    "            }\n",
    "\n",
    "            function renderContext(iterId, turnIdx) {\n",
    "                const d = window.CONVO_DATA[iterId];\n",
    "                if (!d) return \"<div class='ctx-block'><div class='ctx-label'>Context:</div><div>(Context unavailable for this item.)</div></div>\";\n",
    "                const pos = d.assistant_turn_positions[String(turnIdx)];\n",
    "                if (pos == null) {\n",
    "                    return \"<div class='ctx-block'><div class='ctx-label'>Context:</div><div>(Context unavailable for this item.)</div></div>\";\n",
    "                }\n",
    "                const transcript = d.transcript;\n",
    "\n",
    "                // Collect preceding contiguous user messages\n",
    "                let j = pos - 1;\n",
    "                const userMsgs = [];\n",
    "                while (j >= 0 && transcript[j] && transcript[j].role === 'user') {\n",
    "                    userMsgs.push(transcript[j]);\n",
    "                    j -= 1;\n",
    "                }\n",
    "                userMsgs.reverse();\n",
    "\n",
    "                let htmlParts = [\"<div class='ctx-block'><div class='ctx-label'>Context:</div>\"];\n",
    "                for (const um of userMsgs) {\n",
    "                    htmlParts.push(\n",
    "                        \"<div class='message-block message-user'><div class='role-header'>user</div><div class='content'>\"\n",
    "                        + esc(um.content) + \"</div></div>\"\n",
    "                    );\n",
    "                }\n",
    "                const am = transcript[pos] || null;\n",
    "                if (am) {\n",
    "                    htmlParts.push(\n",
    "                        \"<div class='message-block message-assistant'><div class='role-header'>assistant</div><div class='content'>\"\n",
    "                        + esc(am.content) + \"</div></div>\"\n",
    "                    );\n",
    "                }\n",
    "                htmlParts.push(\"</div>\");\n",
    "                return htmlParts.join(\"\");\n",
    "            }\n",
    "\n",
    "            function toggleContent(id) {\n",
    "                const element = document.getElementById(id);\n",
    "                if (!element) return;\n",
    "                const isExpanded = element.classList.contains('expanded');\n",
    "                const header = element.previousElementSibling;\n",
    "                const toggleIcon = header ? header.querySelector('.toggle-icon') : null;\n",
    "                if (isExpanded) {\n",
    "                    element.classList.remove('expanded');\n",
    "                    if (toggleIcon) toggleIcon.textContent = '+';\n",
    "                } else {\n",
    "                    element.classList.add('expanded');\n",
    "                    if (toggleIcon) toggleIcon.textContent = '−';\n",
    "                }\n",
    "            }\n",
    "            function toggleBehItems(id) {\n",
    "                const el = document.getElementById(id);\n",
    "                if (!el) return;\n",
    "                el.classList.toggle('expanded');\n",
    "            }\n",
    "            function openModal(id) {\n",
    "                const el = document.getElementById(id);\n",
    "                if (!el) return;\n",
    "\n",
    "                // Fill context on demand (only once per modal)\n",
    "                const ctxHost = el.querySelector('.ctx-host');\n",
    "                const iterId = el.getAttribute('data-iter-id');\n",
    "                const turnIdx = el.getAttribute('data-turn-idx');\n",
    "\n",
    "                if (ctxHost && !ctxHost.getAttribute('data-rendered')) {\n",
    "                    ctxHost.innerHTML = renderContext(iterId, turnIdx);\n",
    "                    ctxHost.setAttribute('data-rendered', '1');\n",
    "                }\n",
    "\n",
    "                el.classList.add('show');\n",
    "                document.body.classList.add('modal-open'); // lock background scroll\n",
    "                document.addEventListener('keydown', escCloser);\n",
    "            }\n",
    "            function closeModal(id) {\n",
    "                const el = document.getElementById(id);\n",
    "                if (!el) return;\n",
    "                el.classList.remove('show');\n",
    "                // if no other open modals, unlock body\n",
    "                if (document.querySelectorAll('.modal-backdrop.show').length === 0) {\n",
    "                    document.body.classList.remove('modal-open');\n",
    "                }\n",
    "                document.removeEventListener('keydown', escCloser);\n",
    "            }\n",
    "            function escCloser(e) {\n",
    "                if (e.key === 'Escape') {\n",
    "                    document.querySelectorAll('.modal-backdrop.show').forEach(m => m.classList.remove('show'));\n",
    "                    document.body.classList.remove('modal-open');\n",
    "                }\n",
    "            }\n",
    "            function modalBackdropClick(e) {\n",
    "                if (e.target.classList.contains('modal-backdrop')) {\n",
    "                    e.target.classList.remove('show');\n",
    "                    if (document.querySelectorAll('.modal-backdrop.show').length === 0) {\n",
    "                        document.body.classList.remove('modal-open');\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "\n",
    "            \n",
    "            // defer grabbing toggle after DOM is ready — we call setDarkMode when the toggle exists\n",
    "            const STORAGE_KEY = 'chatlogViewerDarkMode';\n",
    "            function setDarkMode(isDark) {\n",
    "                // re-fetch body after DOM is available (don’t cache early)\n",
    "                const b = document.body;\n",
    "                if (b) b.classList.toggle('dark-mode', isDark);\n",
    "\n",
    "                const darkModeToggle = document.getElementById('darkModeToggle');\n",
    "                const toggleLabel = document.getElementById('toggleLabel');\n",
    "                if (toggleLabel) toggleLabel.textContent = isDark ? 'Dark' : 'Light';\n",
    "                if (darkModeToggle && darkModeToggle.checked !== isDark) darkModeToggle.checked = isDark;\n",
    "                localStorage.setItem(STORAGE_KEY, isDark);\n",
    "            }\n",
    "\n",
    "            window.addEventListener('DOMContentLoaded', () => {\n",
    "                const darkModeToggle = document.getElementById('darkModeToggle');\n",
    "                const savedMode = localStorage.getItem(STORAGE_KEY);\n",
    "                const initialDark = (savedMode === 'true') || (savedMode === null && window.matchMedia('(prefers-color-scheme: dark)').matches);\n",
    "                setDarkMode(initialDark);\n",
    "                if (darkModeToggle) {\n",
    "                    darkModeToggle.addEventListener('change', (e) => setDarkMode(e.target.checked));\n",
    "                }\n",
    "            });\n",
    "        </script>\n",
    "    \"\"\"\n",
    "\n",
    "    # Start building the HTML\n",
    "    html_output = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <title>Chatlogs: {html.escape(display_model_name)}</title>\n",
    "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
    "        {css_styles}\n",
    "        {js_scripts_header}\n",
    "    </head>\n",
    "    <body>\n",
    "        <div class=\"top-controls\">\n",
    "            <div class=\"mode-toggle\">\n",
    "                <input class=\"form-check-input\" type=\"checkbox\" id=\"darkModeToggle\">\n",
    "                <label class=\"form-check-label\" for=\"darkModeToggle\" id=\"toggleLabel\">Light</label>\n",
    "            </div>\n",
    "        </div>\n",
    "        <h1>{html.escape(display_model_name)}</h1>\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Helpers ---\n",
    "    def _norm_name(name: str) -> str:\n",
    "        # normalize behavior key for filtering and display\n",
    "        s = (name or \"\").strip()\n",
    "        s = s.replace(\"_\", \" \").lower()\n",
    "        return s\n",
    "\n",
    "    def _cap_first(name: str) -> str:\n",
    "        if not name:\n",
    "            return name\n",
    "        return name[:1].upper() + name[1:]\n",
    "\n",
    "    # --- Loop through all conversations ---\n",
    "    convo_count = 0\n",
    "    # Collect per-convo registration scripts here and append once per convo\n",
    "    convo_reg_scripts: List[str] = []\n",
    "\n",
    "    for run_id, run_content in run_data.items():\n",
    "        for file_key, file_content in run_content.items():\n",
    "            for prompt_key, convos in file_content.items():\n",
    "                for convo_index, convo_data in enumerate(convos):\n",
    "                    if not convo_data or not convo_data.get(\"transcript\"):\n",
    "                        continue\n",
    "                    convo_count += 1\n",
    "\n",
    "                    transcript = convo_data.get(\"transcript\", [])\n",
    "                    judgements = convo_data.get(\"judgements\", {})\n",
    "                    category = convo_data.get(\"category\", \"N/A\")\n",
    "\n",
    "                    iter_id = f\"iter-{run_id}-{prompt_key.replace('.', '-')}-{convo_index}\"\n",
    "                    header_text = f\"{category} &mdash; {prompt_key}\"\n",
    "\n",
    "                    # Build a mapping: assistant_turn_index (1-based) -> list of (chunk_key, judgement_data)\n",
    "                    judgement_map: Dict[int, List[Tuple[str, Dict[str, Any]]]] = defaultdict(list)\n",
    "                    if isinstance(judgements, dict):\n",
    "                        for chunk_key in sorted(judgements.keys(), key=_chunk_sort_key):\n",
    "                            jd = judgements.get(chunk_key, {})\n",
    "                            if not isinstance(jd, dict):\n",
    "                                continue\n",
    "                            idxs = jd.get(\"assistant_turn_indexes\")\n",
    "                            if isinstance(idxs, list) and idxs:\n",
    "                                for idx in idxs:\n",
    "                                    try:\n",
    "                                        turn_idx = int(idx) + 1  # 0-based → display is 1-based\n",
    "                                        judgement_map[turn_idx].append((chunk_key, jd))\n",
    "                                    except (TypeError, ValueError):\n",
    "                                        pass\n",
    "\n",
    "                    # Precompute assistant turn -> transcript index for context building (store in JS later)\n",
    "                    assistant_turn_positions: Dict[int, int] = {}\n",
    "                    a_count = 0\n",
    "                    for i, m in enumerate(transcript):\n",
    "                        if i == 0:\n",
    "                            continue\n",
    "                        if m.get(\"role\") == \"assistant\":\n",
    "                            a_count += 1\n",
    "                            assistant_turn_positions[a_count] = i\n",
    "\n",
    "                    # Intensity tier selection (purple→blue)\n",
    "                    def intensity_class(v):\n",
    "                        try: x = float(v)\n",
    "                        except: return \"int-low\"\n",
    "                        if x >= 3: return \"int-crit\"  # blue\n",
    "                        if x >= 2: return \"int-high\"  # indigo\n",
    "                        if x >= 1: return \"int-med\"   # purple\n",
    "                        return \"int-low\"              # lavender\n",
    "\n",
    "                    behavior_totals: Dict[str, float] = defaultdict(float)\n",
    "                    behavior_entries: Dict[str, List[Dict[str, Any]]] = defaultdict(list)\n",
    "                    chunk_order_cache: Dict[str, int] = {}\n",
    "\n",
    "                    for turn_idx, items in judgement_map.items():\n",
    "                        for (chunk_key, jd) in items:\n",
    "                            chunk_order_cache.setdefault(chunk_key, _chunk_sort_key(chunk_key))\n",
    "                            metrics = jd.get(\"metrics\") or {}\n",
    "                            for bname, val in metrics.items():\n",
    "                                try:\n",
    "                                    behavior_totals[bname] += float(val)\n",
    "                                except Exception:\n",
    "                                    pass\n",
    "                            full = jd.get(\"full_metrics\") or {}\n",
    "                            for bname, lst in full.items():\n",
    "                                if not isinstance(lst, list):\n",
    "                                    continue\n",
    "                                # filter ignore list\n",
    "                                if _norm_name(bname) in IGNORED_CATEGORIES:\n",
    "                                    continue\n",
    "                                for k_i, pair in enumerate(lst):\n",
    "                                    if (isinstance(pair, list) or isinstance(pair, tuple)) and len(pair) >= 2:\n",
    "                                        snippet, sev = pair[0], pair[1]\n",
    "                                        entry = {\n",
    "                                            \"behavior\": bname,\n",
    "                                            \"snippet\": str(snippet),\n",
    "                                            \"intensity\": sev,  # renamed\n",
    "                                            \"intensity_class\": intensity_class(sev),\n",
    "                                            \"turn_idx\": turn_idx,\n",
    "                                            \"chunk_key\": chunk_key,\n",
    "                                            \"chunk_order\": chunk_order_cache[chunk_key],\n",
    "                                            \"modal_id\": f\"modal-{iter_id}-{chunk_key}-{re.sub(r'[^a-zA-Z0-9]+','-', _norm_name(bname))}-{turn_idx}-{k_i}\"\n",
    "                                        }\n",
    "                                        behavior_entries[bname].append(entry)\n",
    "\n",
    "                    # Sort entries by (intensity desc, chunk order asc, turn_idx asc)\n",
    "                    for bname, entries in behavior_entries.items():\n",
    "                        entries.sort(key=lambda e: (-float(e.get(\"intensity\", 0) or 0), int(e.get(\"chunk_order\", 10**9)), int(e.get(\"turn_idx\", 10**9))))\n",
    "\n",
    "                    # Register this conversation's transcript ONCE in JS\n",
    "                    # Keep only role/content pairs to minimize size\n",
    "                    safe_transcript = [{\"role\": str(m.get(\"role\",\"\")), \"content\": str(m.get(\"content\",\"\"))} for m in transcript]\n",
    "                    js_reg = f\"\"\"\n",
    "                        <script>\n",
    "                            (function() {{\n",
    "                                window.CONVO_DATA = window.CONVO_DATA || Object.create(null);\n",
    "                                window.CONVO_DATA[{json.dumps(iter_id)}] = {{\n",
    "                                    transcript: {json.dumps(safe_transcript)},\n",
    "                                    assistant_turn_positions: {json.dumps({str(k): v for k, v in assistant_turn_positions.items()})}\n",
    "                                }};\n",
    "                            }})();\n",
    "                        </script>\n",
    "                    \"\"\"\n",
    "                    convo_reg_scripts.append(js_reg)\n",
    "\n",
    "                    # Build the convo block\n",
    "                    html_output += f\"\"\"\n",
    "                    <div class=\"iteration-container\">\n",
    "                        <div class=\"iteration-header\" onclick=\"toggleContent('{iter_id}')\">\n",
    "                            <span class=\"toggle-icon\">+</span> {header_text}\n",
    "                        </div>\n",
    "                        <div id=\"{iter_id}\" class=\"collapsible-content\">\n",
    "                            <div class=\"content-block\">\n",
    "                                \n",
    "                    \"\"\"\n",
    "\n",
    "                    # --- Behavior Viewer (only if we have entries) ---\n",
    "                    if behavior_entries:\n",
    "                        beh_html = [\"<div class='beh-viewer'>\",\n",
    "                                    \"<div class='beh-summary-title'>Behaviors Identified by LLM Judge:</div>\"]\n",
    "                        # Order behaviors by total desc (still used for overall ordering), then name asc\n",
    "                        ordered = sorted(\n",
    "                            ((b, behavior_totals.get(b, 0.0)) for b in behavior_entries.keys()),\n",
    "                            key=lambda kv: (-float(kv[1] or 0), kv[0])\n",
    "                        )\n",
    "                        for bname, _total in ordered:\n",
    "                            entries = behavior_entries.get(bname, [])\n",
    "                            if not entries:\n",
    "                                continue\n",
    "                            sec_id = f\"beh-items-{iter_id}-{re.sub(r'[^a-zA-Z0-9]+','-', _norm_name(bname))}\"\n",
    "                            # Show only \"Findings: N\"\n",
    "                            beh_html.append(f\"\"\"\n",
    "                                <div class=\"beh-section\">\n",
    "                                    <div class=\"beh-header\" onclick=\"toggleBehItems('{sec_id}')\">\n",
    "                                        <div class=\"beh-name\">{html.escape(_cap_first(_norm_name(bname)))}</div>\n",
    "                                        <div class=\"beh-meta\">Findings: {len(entries)}</div>\n",
    "                                    </div>\n",
    "                                    <div id=\"{sec_id}\" class=\"beh-items\">\n",
    "                            \"\"\")\n",
    "                            for e in entries:\n",
    "                                snippet = html.escape(e[\"snippet\"])\n",
    "                                intensity = e[\"intensity\"]\n",
    "                                int_cls = e[\"intensity_class\"]\n",
    "                                mdl = e[\"modal_id\"]\n",
    "                                beh_html.append(f\"\"\"\n",
    "                                    <div class=\"beh-item\">\n",
    "                                        <span class=\"int-badge {int_cls}\" title=\"Intensity\">{html.escape(str(intensity))}</span>\n",
    "                                        <div class=\"beh-snippet\">\n",
    "                                            <span class=\"beh-link\" onclick=\"openModal('{mdl}')\">{snippet}</span>\n",
    "                                            <span class=\"beh-idx\">[after assistant turn {e['turn_idx']}]</span>\n",
    "                                        </div>\n",
    "                                    </div>\n",
    "                                \"\"\")\n",
    "                            beh_html.append(\"</div></div>\")\n",
    "                        beh_html.append(\"</div>\")\n",
    "                        html_output += \"\".join(beh_html)\n",
    "\n",
    "                        # Modals for all entries (context is now injected dynamically)\n",
    "                        for bname, entries in behavior_entries.items():\n",
    "                            for e in entries:\n",
    "                                mdl = e[\"modal_id\"]\n",
    "                                quote_html = f\"<div class='quote-callout'>{html.escape(e['snippet'])}</div>\"\n",
    "                                modal_title = f\"Behaviour identified: {html.escape(_cap_first(_norm_name(bname)))} &middot; Intensity {html.escape(str(e['intensity']))} &middot; Turn {html.escape(str(e['turn_idx']))}\"\n",
    "                                html_output += f\"\"\"\n",
    "                                    <div id=\"{mdl}\" class=\"modal-backdrop\" onclick=\"modalBackdropClick(event)\"\n",
    "                                         data-iter-id=\"{iter_id}\" data-turn-idx=\"{e['turn_idx']}\">\n",
    "                                      <div class=\"modal-card\">\n",
    "                                        <div class=\"modal-head\">\n",
    "                                          <div class=\"modal-title\">{modal_title}</div>\n",
    "                                          <div class=\"modal-close\" onclick=\"closeModal('{mdl}')\">&times;</div>\n",
    "                                        </div>\n",
    "                                        <div class=\"modal-body\">\n",
    "                                          {quote_html}\n",
    "                                          <div class=\"ctx-host\"></div>\n",
    "                                        </div>\n",
    "                                      </div>\n",
    "                                    </div>\n",
    "                                \"\"\"\n",
    "                    html_output += f\"\"\"\n",
    "                                <div class=\"prompt-text-display\">\n",
    "                                    <strong>Initial User Prompt:</strong><br>{html.escape(transcript[0]['content'])}\n",
    "                                </div>\n",
    "                                \"\"\"\n",
    "\n",
    "                    # --- Messages + judge blocks (existing behavior preserved) ---\n",
    "                    assistant_turn_counter = 0  # 1-based counter of assistant messages\n",
    "                    for i, message in enumerate(transcript):\n",
    "                        if i == 0:\n",
    "                            continue  # initial prompt already shown\n",
    "\n",
    "                        role = message['role']\n",
    "                        content = message['content']\n",
    "\n",
    "                        html_output += f\"\"\"\n",
    "                                <div class=\"message-block message-{role}\">\n",
    "                                    <div class=\"role-header\">{html.escape(role)}</div>\n",
    "                                    <div class=\"content\">{html.escape(content)}</div>\n",
    "                                </div>\n",
    "                        \"\"\"\n",
    "\n",
    "                        # After an assistant message, insert any judge blocks that target this assistant turn\n",
    "                        if role == 'assistant':\n",
    "                            assistant_turn_counter += 1\n",
    "\n",
    "                            if judgement_map:\n",
    "                                for chunk_key, judgement_data in judgement_map.get(assistant_turn_counter, []):\n",
    "                                    judge_id = f\"judge-{iter_id}-{chunk_key}\"\n",
    "                                    raw_text = judgement_data.get(\"raw_text\", \"<i>No raw text provided.</i>\")\n",
    "                                    metrics = judgement_data.get(\"metrics\", {})\n",
    "                                    error = judgement_data.get(\"error\")\n",
    "\n",
    "                                    html_output += f\"\"\"\n",
    "                                    <div class=\"judge-header\" onclick=\"toggleContent('{judge_id}')\">\n",
    "                                       <span class=\"toggle-icon\">+</span> Judge Evaluation (After Assistant Turn {assistant_turn_counter})\n",
    "                                    </div>\n",
    "                                    <div id=\"{judge_id}\" class=\"collapsible-content collapsible-judge-content\">\n",
    "                                        <div class=\"judge-content\">\n",
    "                                    \"\"\"\n",
    "                                    if error:\n",
    "                                        html_output += f\"<strong>Error during judging:</strong><br>{html.escape(str(error))}\"\n",
    "                                    else:\n",
    "                                        scores_html = \"<ul>\"\n",
    "                                        for metric, value in sorted(metrics.items()):\n",
    "                                            scores_html += f\"<li><strong>{html.escape(metric)}:</strong> {html.escape(str(value))}</li>\"\n",
    "                                        scores_html += \"</ul>\"\n",
    "\n",
    "                                        html_output += f\"\"\"\n",
    "                                            <strong>Scores:</strong>\n",
    "                                            {scores_html}\n",
    "                                            <hr style='margin: 10px 0; border-top: 1px solid var(--border-color);'>\n",
    "                                            <strong>Judge Raw Output:</strong><br>\n",
    "                                            <div style=\"white-space: pre-wrap;\">{html.escape(raw_text)}</div>\n",
    "                                        \"\"\"\n",
    "                                    html_output += \"\"\"\n",
    "                                        </div>\n",
    "                                    </div>\n",
    "                                    \"\"\"\n",
    "                            else:\n",
    "                                # Fallback for older results without assistant_turn_indexes\n",
    "                                if JUDGE_CHUNK_SIZE and assistant_turn_counter % JUDGE_CHUNK_SIZE == 0:\n",
    "                                    chunk_idx = (assistant_turn_counter // JUDGE_CHUNK_SIZE) - 1\n",
    "                                    chunk_key = f\"chunk{chunk_idx}\"\n",
    "                                    judgement_data = judgements.get(chunk_key)\n",
    "                                    if judgement_data:\n",
    "                                        judge_id = f\"judge-{iter_id}-{chunk_key}\"\n",
    "                                        raw_text = judgement_data.get(\"raw_text\", \"<i>No raw text provided.</i>\")\n",
    "                                        metrics = judgement_data.get(\"metrics\", {})\n",
    "                                        error = judgement_data.get(\"error\")\n",
    "\n",
    "                                        html_output += f\"\"\"\n",
    "                                        <div class=\"judge-header\" onclick=\"toggleContent('{judge_id}')\">\n",
    "                                           <span class=\"toggle-icon\">+</span> Judge Evaluation (Turns {assistant_turn_counter - JUDGE_CHUNK_SIZE + 1}&ndash;{assistant_turn_counter})\n",
    "                                        </div>\n",
    "                                        <div id=\"{judge_id}\" class=\"collapsible-content collapsible-judge-content\">\n",
    "                                            <div class=\"judge-content\">\n",
    "                                        \"\"\"\n",
    "                                        if error:\n",
    "                                            html_output += f\"<strong>Error during judging:</strong><br>{html.escape(str(error))}\"\n",
    "                                        else:\n",
    "                                            scores_html = \"<ul>\"\n",
    "                                            for metric, value in sorted(metrics.items()):\n",
    "                                                scores_html += f\"<li><strong>{html.escape(metric)}:</strong> {html.escape(str(value))}</li>\"\n",
    "                                            scores_html += \"</ul>\"\n",
    "\n",
    "                                            html_output += f\"\"\"\n",
    "                                                <strong>Scores:</strong>\n",
    "                                                {scores_html}\n",
    "                                                <hr style='margin: 10px 0; border-top: 1px solid var(--border-color);'>\n",
    "                                                <strong>Judge Raw Output:</strong><br>\n",
    "                                                <div style=\"white-space: pre-wrap;\">{html.escape(raw_text)}</div>\n",
    "                                            \"\"\"\n",
    "                                        html_output += \"\"\"\n",
    "                                            </div>\n",
    "                                        </div>\n",
    "                                        \"\"\"\n",
    "\n",
    "                    html_output += \"\"\"\n",
    "                            </div>\n",
    "                        </div>\n",
    "                    </div>\n",
    "                    \"\"\"\n",
    "\n",
    "    if convo_count == 0:\n",
    "        html_output += \"<h2>No valid conversations found in this file.</h2>\"\n",
    "\n",
    "    # Append all per-convo registration scripts once at the end of the body to avoid interleaving\n",
    "    html_output += \"\\n\".join(convo_reg_scripts)\n",
    "\n",
    "    html_output += \"\"\"\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "    # Save to file if requested\n",
    "    if save_to_file:\n",
    "        output_filename = os.path.splitext(os.path.basename(file_path))[0] + \".html\"\n",
    "        full_output_path = os.path.join(OUTPUT_DIR, output_filename)\n",
    "        os.makedirs(os.path.dirname(full_output_path), exist_ok=True)\n",
    "        try:\n",
    "            with open(full_output_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(html_output)\n",
    "            print(f\"  Report saved to {full_output_path}\")\n",
    "        except IOError as e:\n",
    "            print(f\"  Error saving report to {full_output_path}: {e}\", file=sys.stderr)\n",
    "\n",
    "    return HTML(html_output)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ## Main Execution Block\n",
    "\n",
    "if __name__ == \"__main__\" or 'IPython' in sys.modules:\n",
    "    print(f\"--- Generating Chatlog Reports ---\")\n",
    "    print(f\"Source Directory: {os.path.abspath(RUNS_SOURCE_DIR)}\")\n",
    "    print(f\"Output Directory: {os.path.abspath(OUTPUT_DIR)}\")\n",
    "    \n",
    "    json_files = sorted(glob.glob(os.path.join(RUNS_SOURCE_DIR, \"*.json\")))\n",
    "    \n",
    "    if not json_files:\n",
    "        print(\"\\nNo JSON files found. Please check the `RUNS_SOURCE_DIR` path.\")\n",
    "    else:\n",
    "        print(f\"\\nFound {len(json_files)} result files to process.\")\n",
    "        \n",
    "        # Generate and save a report for every file\n",
    "        for i, file_path in enumerate(json_files):\n",
    "            report_html = generate_chatlog_report(file_path, save_to_file=True)\n",
    "            if i == 0 and report_html:\n",
    "                print(\"\\nDisplaying first report in notebook:\")\n",
    "                # display(report_html)\n",
    "\n",
    "        print(\"\\n--- Script finished. ---\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
